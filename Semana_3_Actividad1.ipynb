{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "# Fundamentos de Bases de Datos\n",
        "\n",
        "*Materia: Ciencia y Analítica de Datos*\n",
        "\n",
        "*Profesor: Jobish Vallikavungal*\n",
        "\n",
        "*A01273800 José Eduardo Arteaga Valdés*\n",
        "\n",
        "*A01793499 Diego Fernando Guerra Burgos*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "NJCGDzuw8KK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte 1: Fundamentos de Bases de Datos**\n",
        "\n",
        "1. Fundamentos de bases de datos y para ciencia de datos.\n",
        "\n",
        "En primer lugar, se debe definir lo que es una base de datos. La base de datos es un programa de computadora (o la nube) dentro del cual se almacenan datos de una manera estructurada (generalmente en filas y columnas para datos estructurados). Otra característica de la base de datos es que pueda ser accesible a través de un programa informático para se pueda realizar estudios y análisis sobre la misma \n",
        "Dentro de la ciencia de datos, la base de datos es la pieza fundamental e importante para cualquier proyecto, principalmente, porque aquí están los datos que se van a utilizar/transformar para el análisis del proyecto. Gran parte del trabajo del científico de datos está centrado en las bases de datos. El científico de datos debe acceder y conocer a profundidad la base de datos para saber qué tipo de datos están almacenados, cuáles son de utilidad para el proyecto y cómo resolver el problema de información que falta (NA values) dentro de la base. También porque el científico de datos puede identificar nuevas variables que puede transformar y crear nuevas bases de datos que serán utilizadas en otras partes del proyecto (en especial cuando existe un modelo, se crearon 3 tipos de bases de datos para examinar su desempeño).    \n",
        "\n",
        "2. Fundamentos de almacenes de datos (Data Warehouse) para ciencia de datos.\n",
        "\n",
        "Los Data Warehouses actúan como una gran base de datos que recaba información de diferentes canales. Es decir, es una herramienta de centralización de datos. Por ejemplo, una agencia de mercadotecnia podría recibir información de sus prospectos vía mail, un formulario web, datos de redes sociales o datos de Google ads. Por ello mismo, conlleva dos retos importantes: primero, el de normalizar todos los registros en un formato único y estándar, sin perder información; y segundo, el de contar con la fuerza computacional necesaria para la gran cantidad de datos. En relación al segundo reto, se cuenta con dos tipos de Warehouses (o de manera de procesar los datos en un Warehouse):\n",
        "\n",
        "**ETL = Extract, Transform & Load**\n",
        "> Primero, se extraen los datos de una fuente de información. Después se transforman (normalizan) al formato ideal y se terminan por cargar en el Data Warehouse.\n",
        "\n",
        "> La desventaja: la etapa de Transform se realiza offline. Por lo que, a más datos, mayor tiempo y recursos necesarios para procesarse. Puede ser un proceso lento.\n",
        "\n",
        "**ELT = Extract, Load & Transform**\n",
        "> Primero, se extraen los datos de una fuente de información. Se cargan tal como están (raw) a un intermediario con el Data Warehouse. Y una vez cargados, se usa una herramienta como Hadoop(1) para transformarlos.\n",
        "\n",
        "> La ventaja: Hadoop acelera el proceso de transformar los datos ya que no se realiza offline - se utiliza el poder del cloud computing. *“Once again, you first extract your raw data, but then we're going to load it into the data warehouse system itself as is. And, then use the power of the data warehouse, which might be built on Hadoop, to do that transformation as the third step.”* (Kane, 2017).\n",
        "\n",
        "(1) *“Hadoop es una estructura de software de código abierto para almacenar datos y ejecutar aplicaciones en clústeres de hardware comercial. Proporciona almacenamiento masivo para cualquier tipo de datos, enorme poder de procesamiento y la capacidad de procesar tareas o trabajos concurrentes virtualmente ilimitados.”* (sas, 2022) \n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "JU8R3SQQ8r_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte 2: Selección y limpieza de los Datos en Python**\n",
        "\n"
      ],
      "metadata": {
        "id": "LE72hw2mnmpt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaFkNyIgmJc5"
      },
      "outputs": [],
      "source": [
        "# importamos las librerias necesarias para la limpieza\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos la base de datos que vamos a utilizar para el ejercicio (en este paso cambiar el path a donde se encuentre el archivo en la computadora de quien ejecute el código)"
      ],
      "metadata": {
        "id": "oeFpUVMrmNNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('C:/Users/DIEGO/Desktop/Outsider Picks/Actividad/default of credit card clients.csv', index_col=0)"
      ],
      "metadata": {
        "id": "vBSKP2KpmMJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una lista que contiene los nombres de las columnas establecidas en la descripcion"
      ],
      "metadata": {
        "id": "kw2WvBvLmTFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['credit_given', 'gender', 'education', 'marital_status', 'age', 'payment_status_sep_05', 'payment_status_aug_05',\n",
        "                'payment_status_jul_05', 'payment_status_jun_05', 'payment_status_may_05', 'payment_status_apr_05', 'bill_statement_sep_05',\n",
        "                'bill_statement_aug_05', 'bill_statement_jul_05', 'bill_statement_jun_05', 'bill_statement_may_05', 'bill_statement_apr_05',\n",
        "                'previous_statement_sep_05', 'previous_statement_aug_05', 'previous_statement_jul_05', 'previous_statement_jun_05', 'previous_statement_may_05',\n",
        "                'previous_statement_apr_05', 'default']\n",
        "\n",
        "#procedemos a cambiar los nombres de las columnas en nuestro df con la lista que cree\n",
        "df.columns = column_names"
      ],
      "metadata": {
        "id": "3_CB3ZUomVVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buscamos si existen valores faltantes en la base"
      ],
      "metadata": {
        "id": "KcMdA70ymcIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().values.any()\n",
        "\n",
        "#Dado que nos regresa True, buscamos por columna\n",
        "df.isna().any()\n",
        "\n",
        "#Contamos todos los valores restantes por columna para saber cuantos datos podríamos perder si decidimos eliminar los NA\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "xRSmfcsgmhNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando estos resultados, en las variables categóricas (gender, education, marital_status y default) se puede eliminar los NA dado que no se pueden determinar con otros métodos y son pocos datos en relación al total.\n",
        "También se puede eliminar los NA de las variables de payment_status que representan el número de meses que no se ha generado pagos"
      ],
      "metadata": {
        "id": "fqHKjQ9HmpOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "payment_status_columns = [string for string in column_names if 'payment_status' in string]\n",
        "clean_df = df.copy()\n",
        "clean_df.dropna(subset = ['gender', 'education', 'marital_status', 'default'], inplace = True)\n",
        "clean_df.dropna(subset= payment_status_columns, inplace = True)\n",
        "print (df.shape[0] - clean_df.shape[0], 'filas han sido eliminadas por NA en variables categóricas')"
      ],
      "metadata": {
        "id": "5PNZ67DFms2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que eliminamos los valores faltantes, nos aseguramos que cumplan con el formato establecido en la descripción por ejemplo, gender puede ser 1 o 2 (no puede tener decimales)"
      ],
      "metadata": {
        "id": "JEThG_-6mxh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filas_iniciales = clean_df.shape[0]\n",
        "\n",
        "clean_df = clean_df[(clean_df['gender'] == 1) | (clean_df['gender'] == 2)]\n",
        "\n",
        "#education solamente puede tener valores de 1, 2, 3 y 4\n",
        "clean_df = clean_df[(clean_df['education'] == 1) | (clean_df['education'] == 2)| (clean_df['education'] == 3) | (clean_df['education'] == 4)]\n",
        "\n",
        "#marital_status solo puede tener valores de 1,2 y 3\n",
        "clean_df = clean_df[(clean_df['marital_status'] == 1) | (clean_df['marital_status'] == 2) | (clean_df['marital_status'] == 3)]\n",
        "\n",
        "#default solo puede tener valores binarios 1 y 0\n",
        "clean_df = clean_df[(clean_df['default'] == 1) | (clean_df['default'] == 0)]\n",
        "\n",
        "filas_finales = clean_df.shape[0]\n",
        "print ('Se eliminó', filas_iniciales-filas_finales, 'registros que contenían formatos incorrectos de variables categóricas')"
      ],
      "metadata": {
        "id": "VUaHr310m3pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos una base de datos con todas las variables categóricas sin NA arreglemos los NA en edad utilizando la media de la edad de toda nuestra población."
      ],
      "metadata": {
        "id": "GoFSa78AnAYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df['age'].fillna(value = clean_df.age.mean(), inplace = True)\n",
        "#comprobamos que no existan NA después de nustro arreglo\n",
        "if clean_df.age.isna().any() == False:\n",
        "    print ('No hay valores NA en la columna age')\n",
        "else:\n",
        "    print ('fill NA con media de age no funcionó')\n",
        "\n",
        "#ya que el promedio puede tener decimales y la edad no puede tener valores decimales, convertimos la columna a integer\n",
        "clean_df = clean_df.astype({'age':'int'})"
      ],
      "metadata": {
        "id": "-EeVme_fnEew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solamente nos quedan las variables de información mensual de los pagos y estados de cuenta de cada cliente\n",
        "Tenemos 18 columnas que representan 6 meses de información\n",
        "Para esto utlizaremos el método Treshold\n",
        "En primer lugar eliminaremos todas las filas que tengan info faltante en más de la mitad de estas 18 columnas"
      ],
      "metadata": {
        "id": "KAzWPsHLnHZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filas_iniciales = clean_df.shape[0]\n",
        "clean_df.dropna(thresh=9, inplace = True)\n",
        "filas_finales = clean_df.shape[0]\n",
        "print ('Se eliminó', filas_iniciales-filas_finales, 'registros')"
      ],
      "metadata": {
        "id": "lj5j4ngFnLQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "De esta manera obtenemos que existen pocos valores NA (máximo 6) en el resto de columnas, así que decidimos eliminar estas columnas de nuestra base\n",
        "No utilizamos promedio o media porque cada statement es específico para cada cliente."
      ],
      "metadata": {
        "id": "U8p_KaMwnNk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filas_iniciales = clean_df.shape[0]\n",
        "clean_df.dropna(inplace = True)\n",
        "filas_finales = clean_df.shape[0]\n",
        "print ('Se eliminó', filas_iniciales-filas_finales, 'registros de NA en columnas de statement')"
      ],
      "metadata": {
        "id": "WzIuTovonRwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos que no existen valores NA en mi base"
      ],
      "metadata": {
        "id": "VMeBOunMnTxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df.isna().values.any()"
      ],
      "metadata": {
        "id": "FRfnHfubnVpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos un reporte de los valores eliminados en el proceso de limpieza"
      ],
      "metadata": {
        "id": "ExeB24xjnY6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Se eliminaron', df.shape[0] - clean_df.shape[0], 'registros en el proceso de limpieza de datos')"
      ],
      "metadata": {
        "id": "4wurBtxvnbc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte 3: Preparación de los datos**\n",
        "\n",
        "Con base en los resultados de tu libreta de Google Colab de la Parte 2 responde detalladamente las siguientes preguntas: \n",
        "\n",
        "1. **¿Qué datos considero más importantes? ¿Por qué?**\n",
        "\n",
        "Los datos más importantes son las 18 columnas que reflejan información de los estados de cuenta de los 6 meses que estamos analizando en esta base al igual que el valor del crédito que se otorgó a cada cliente. Son los más importantes porque contienen la información del comportamiento de los pagos del consumidor y junto con la variable Default podemos determinar qué tipo de comportamientos pueden llevar a que un cliente no sea creíble (pueda caer en default).  \n",
        "\n",
        "2. **¿Se eliminaron o reemplazaron datos nulos? ¿Qué se hizo y por qué?**\n",
        "\n",
        "Se eliminaron y reemplazaron datos nulos. \n",
        "\n",
        "En primer lugar, eliminamos los datos nulos de las variables categóricas, por 2 razones, eran pocos valores en relación con el total de la base (5 en total) y al ser variables de categoría no existe forma de determinar sus valores con funciones matemáticas (media, mediana, moda, min, max, etc..). También eliminamos los datos de estas variables que reflejaban valores fuera de su descripción, por ejemplo, en la columna education existían filas que contenían valores 5 o 6 y la descripción de la base de datos establecía que esta variable solamente podía reflejar valores 1, 2, 3 y 4.  Esto se aplicó en 10 columnas (gender, education, marital_status, default y las 6 columnas de payment_status) \n",
        "\n",
        "En segundo lugar, reemplazamos datos nulos en la columna de edad con el promedio de la población y posteriormente se cambiaron los valores a enteros (integer). \n",
        "\n",
        "Tras este proceso de eliminación y reemplazo, se procedió a eliminar los restantes valores NA de la base por 2 razones:\n",
        "\n",
        "* Representaban un valor muy bajo sobre la base (14 de 30000)\n",
        "* No se podía reemplazar con otros valores como media o mediana porque cada valor era específico para cada cliente (un promedio resultaría atípico).\n",
        "\n",
        "3. **¿Es necesario limpiar los datos para el análisis? Sí / No / ¿Por qué?**\n",
        "\n",
        "Si es necesario limpiar los datos para el análisis porque los datos atípicos pueden generar ruido sobre el modelo de predicción. De igual manera, se debe asegurar que los datos se encuentren en el formato adecuado y sean datos de las categorías establecidas porque un dato fuera de categoría afectaría la predicción del modelo. \n",
        "\n",
        "4. **¿Existen problemas de formato que deban solucionar antes del proceso de modelado? Sí / No / Por qué.**\n",
        "\n",
        "Si en la variable de education. En la descripción de la base de datos se establece que la variable education solamente puede tomar valores de 1, 2, 3, 4 y existen valores mayores a 4 que no pueden ser determinados. Estamos hablando de variables categóricas o binarias, si existe un valor que no corresponda a esas categorías, se genera ruido en los parámetros del modelo, lo que podría restar significancia estadística a una variable o una predicción incorrecta si estos datos se encuentran fuera del formato establecido. De igual manera, estas variables deben ser valores enteros (integer). \n",
        "\n",
        "5. **¿Qué ajustes se realizaron en el proceso de limpieza de datos (agregar, integrar, eliminar, modificar registros (filas), cambiar atributos (columnas)?**\n",
        "\n",
        "* En primer lugar, cambiamos los nombres de las columnas. En la base de datos las columnas venían denominadas Xi (i representando el índice de la columna). Utilizamos la información de la descripción de la base para cambiar el nombre de las columnas a las etiquetas correctas para saber exactamente qué variable estamos observando para así poder determinar qué hacer para limpiar los datos de esa columna. \n",
        "* Se eliminaron registros de las variables categóricas que presentaban valores NA (detallado en la pregunta 2).\n",
        "* Se eliminaron valores de variables categóricas que se encontraban fuera de la descripción de la base de datos (en 10 columnas). \n",
        "* Se reemplazó los datos nulos de la columna ‘age’ con el promedio de la edad de población.\n",
        "* Se convirtió los valores de age a enteros (integer)\n",
        "* Se eliminaron registros que tenían NA en más de la mitad de las columnas relacionadas a Statement.\n",
        "* Se eliminaron el resto de los valores NA de la base (era un valor marginal en relación con la base de datos por lo cual su exclusión no tendría impacto sobre el modelo). \n",
        " \n",
        "---\n"
      ],
      "metadata": {
        "id": "5IGriNp6Dy3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referencias**\n",
        "\n",
        "\n",
        "* Kane, F. (2017). Hands-On Data Science and Python Machine Learning. Packt Publishing Recuperado el 2 de octubre de 2022, de: https://newoutlook.it/download/python/hands-on-data-science.pdf\n",
        "\n",
        "*   Metwalli, S. (2020). Databases 101: Introduction to Databases for Data Scientists. Towards Data Science. https://towardsdatascience.com/databases-101-introduction-to-databases-for-data-scientists-ee18c9f0785d\n",
        "\n",
        "* Sas. (2022). Hadoop ¿Qué es y por qué es importante?. Recuperado el 2 de octubre de 2022, de: https://www.sas.com/es_mx/insights/big-data/hadoop.html "
      ],
      "metadata": {
        "id": "zyIHEGleFE1H"
      }
    }
  ]
}